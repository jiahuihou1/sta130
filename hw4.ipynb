{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "The standard deviation of the data set measures the spread of individual data points around their mean, reflecting on the inconstancies within the sample itself, in contrast the standard error of the mean captures the inconsistencies of the sample mean if we were to repeatedly drew samples from the population. It tells us how much the sample mean might deviate from the true population mean, showing the accuracy of our estimate.\n",
    "\n",
    "## 2\n",
    "To create a 95% confidence interval using the standrad error of mean, we have to multiply the standard error by approxiamately 1.96 (for a normal distribution) and add/minus this value from the sample mean. This will give a range that captures 95% of the bootstrapped sample means, helping us estimate where the true mean may likely fall if we were to sample the entire population.\n",
    "\n",
    "## 3 \n",
    "Well, to create a 95% bootstrapped confidence interval WITHOUT using teh standard error, we could simply sort the bootstrapped means and find the 2.5 and 97.5th percentile. These percentiles mark the lower and upper bounds of the confidence interval, as 97.5 - 2.5 = 95%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% bootstrap confidence interval for the mean: (5.078947368421052, 6.894736842105263)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data taken from going to robarts and rating people's opinions on the food trucks right outside\n",
    "sample = np.array([0,1,1,1,1,1,2,4,5,5,5,5,5,5,6,6,6,6,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,10,10,10,10])\n",
    "\n",
    "# num of bootstrap simulatiosn ran\n",
    "n_bootstrap_samples = 10000\n",
    "\n",
    "# create array to store the bootstrap means\n",
    "bootstrap_means = np.empty(n_bootstrap_samples)\n",
    "\n",
    "# Bootstrap resampling\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # sample w/ replacement from the data set\n",
    "    bootstrap_sample = np.random.choice(sample, size=len(sample), replace=True)\n",
    "    \n",
    "    # calculate the mean of the bootstrap sample and store it\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)  # change np.mean to np.median to calculate the median\n",
    "\n",
    "# calculate the 95% confidence interval (2.5 and 97.5th percentiles)\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(f\"95% bootstrap confidence interval for the mean: ({ci_lower}, {ci_upper})\")\n",
    "\n",
    "# to calculate a 95% bootstrap confidence interval for the median, just change \"np.mean\" to \"np.median\"\n",
    "# bootstrap_means[i] = np.median(bootstrap_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \n",
    "Population parameter and sample statistic is different as a population parameter reflects the true value we're intereted in, suhc as the true mean or median, but often times that's unrealistic, whether due to budgeting, time, or effort. Instead, we rely on sample statistics, and methods such as bootstrapping, to estimate based on a subset of population. Because a sample can include outliers/extreme values, using such a small sample size could lead to risks surrounding the fact that the sample statistic might not perfectly represent the population. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "### 1. \n",
    "the process of bootstrapping is that you imagine you've got a small set of data, a sample, and you want to figure out something about the population it came from, for example, the mat157 average (mean) or median. Its basically where we take the sample, and random;ly pick values from it to create a new \"fake\" dataset. The key is that we pick these values WITH replacements, meaning we are allowed to pick the same value more than once. We repeat this a bunch of times, usually using a computer to help us code, around 1000 or 10000 times, to get a \"bootstrapped\" dataset. We then calculate the mean for each one, graph them, and use those results to get a sense of how the sample behaviors. \n",
    "\n",
    "### 2. \n",
    "The main goal of boostrapping is to estimate values such as the mean and median when we cannot get more data from a population due to external restraints. It can help us figure how the results from our sample could change if we were to do this experiment over and over again, essentially allowing us to make better guesses about the population by simulating potential new samples from the existing set of data. \n",
    "\n",
    "### 3. \n",
    "\n",
    "FOllow the instructions of part 1, and create a bunch of bootstrapped samples from your original sample size. Then for each bootstrapped samples, and calcualte the mean and build a distrubution of these means. Once you have this distrubution, check if your hypothesized mean falls within the range of the bootstrapped means (within the 95% confidence interval), if it does, your guess may be plausible. If its close, or WAY outside the range, it shows that your hypothesized average may be off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
